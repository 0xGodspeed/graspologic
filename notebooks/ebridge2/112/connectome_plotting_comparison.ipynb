{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import ndmg.utils as mgu\n",
    "from argparse import ArgumentParser\n",
    "from scipy import ndimage\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib as mpl\n",
    "from nilearn.plotting.edge_detect import _edge_map as edge_map\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import lil_matrix\n",
    "import pandas as pd\n",
    "from plotly.offline import plot, iplot, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "import math\n",
    "from ndmg import timeseries as ndt\n",
    "import csv\n",
    "from ndmg import register as ndr\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def glm_fit(Y, X):\n",
    "    \"\"\"\n",
    "    model Y = XB + E with Y as the voxelwise intensities and X the design matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        Y:\n",
    "            - the voxelwise intensities as a [t, v] matrix.\n",
    "        X:\n",
    "            - the design matrix of regressors as a [t, r] matrix.\n",
    "    Returns\n",
    "    -------\n",
    "        E:\n",
    "            - the residuals not explained by the design matrix.\n",
    "    \"\"\"\n",
    "    # B = (X'X)^(-1)X'Y\n",
    "    B = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)  # the coefs for each regressor\n",
    "    E = Y - X.dot(B)  # E = Y - XB\n",
    "    return E # return residuals not explained by our confound regressors\n",
    "\n",
    "def nuis_correct(brain_file, reg_file, out_file, scrub=5):\n",
    "    \"\"\"\n",
    "    A function for applying nuisance correction to the outputs of\n",
    "    fmriprep.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        - brain_file: string\n",
    "            - the path to the preprocessed fmriprep brain.\n",
    "        - reg_file: string\n",
    "            - the path to a tsv of confounds from fmriprep.\n",
    "        - out_file: string\n",
    "            - the path for the resulting nuisance corrected brain.\n",
    "    Returns\n",
    "    -------\n",
    "        - out_file: string\n",
    "            - the path for the resulting nuisance corrected brain.\n",
    "    \"\"\"\n",
    "    # load inputs\n",
    "    brain_im = nib.load(brain_file)\n",
    "    # generate numpy array from 1:n rows of the confound file\n",
    "    # load the brain data\n",
    "    brain_dat = brain_im.get_data()[:,:,:,scrub:]\n",
    "    reg = np.genfromtxt(reg_file, delimiter='\\t')[1:,:]\n",
    "    # get the regressor names\n",
    "    with open(reg_file) as rf:\n",
    "        reg_names = csv.reader(rf, delimiter='\\t')\n",
    "        names = reg_names.next()\n",
    "    reg = reg[scrub:,:]\n",
    "    # regressors of interest are 6 motion params, acompcor, fd\n",
    "    reg_of_interest = ['a_comp_cor', 'rot_', 'trans_', 'framewise_displacement']\n",
    "    reg_to_use = np.array([any(x in name for x in reg_of_interest) for name in names])\n",
    "    X = reg[:, reg_to_use]  # the design matrix\n",
    "    X = np.column_stack((X, np.ones(X.shape[0])))  # remove mean signal per voxel\n",
    "    X = np.column_stack((X, np.array(range(0, X.shape[0]))))  # remove linear trend per voxel\n",
    "    X = np.column_stack((X, np.array(range(0, X.shape[0]))**2))  # remove quadratic trend per voxel\n",
    "    X[0, 0] = 0  # FD is not defined for first volume, so just start at 0\n",
    "    # reformat the voxelwise timeseries to be [timesteps, voxels]\n",
    "    # a superficial mask so that we don't pull voxels with zero signal\n",
    "    # this would lead to non-invertibility\n",
    "    basic_mask = brain_dat.sum(axis=3) > 0\n",
    "    Y = brain_dat[basic_mask, :].T  # the brain with zero-weight voxels removed, as a [timesteps, voxels] array\n",
    "\n",
    "    B = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)  # the coefs for each regressor\n",
    "    Y_corrected = Y - X.dot(B)  # E = Y - XB\n",
    "\n",
    "    # put back into the data glob\n",
    "    brain_dat[basic_mask, :] = Y_corrected.T\n",
    "    new_im = nib.Nifti1Image(brain_dat, header=brain_im.header, affine=brain_im.affine)\n",
    "    nib.save(new_im, out_file)\n",
    "    return (out_file, basic_mask)\n",
    "\n",
    "\n",
    "def plot_mtx(A, title=\"\"):\n",
    "    \"\"\"\n",
    "    A basic function to plot an adjacency matrix.\n",
    "    \"\"\"\n",
    "    Adf = pd.DataFrame(A).stack().rename_axis(['y', 'x']).reset_index(name=\"Weight\")\n",
    "    trace = go.Heatmap(x=Adf.x, y=Adf.y, z=Adf.Weight)\n",
    "    data = [trace]\n",
    "    layout=go.Layout(width=550, height=550,\n",
    "                     title=title,\n",
    "                     xaxis=dict(title=\"Node Out\"),\n",
    "                     yaxis=dict(title=\"Node In\", autorange=\"reversed\"), validate=False)\n",
    "    fig = go.Figure(data=data, layout=layout, validate=False)\n",
    "    iplot(fig, validate=False)\n",
    "    \n",
    "\n",
    "def opaque_colorscale(basemap, reference, vmin=None, vmax=None, alpha=1):\n",
    "    \"\"\"\n",
    "    A function to return a colorscale, with opacities\n",
    "    dependent on reference intensities.\n",
    "    **Positional Arguments:**\n",
    "        - basemap:\n",
    "            - the colormap to use for this colorscale.\n",
    "        - reference:\n",
    "            - the reference matrix.\n",
    "    \"\"\"\n",
    "    reference = reference\n",
    "    if vmin is not None:\n",
    "        reference[reference > vmax] = vmax\n",
    "    if vmax is not None:\n",
    "        reference[reference < vmin] = vmin\n",
    "    cmap = basemap(reference)\n",
    "    maxval = np.nanmax(reference)\n",
    "    # all values beteween 0 opacity and 1\n",
    "    opaque_scale = alpha*reference/float(maxval)\n",
    "    # remaps intensities\n",
    "    cmap[:, :, 3] = opaque_scale\n",
    "    return cmap\n",
    "\n",
    "\n",
    "def plot_brain(brain, minthr=2, maxthr=95, edge=False):\n",
    "    brain = mgu.get_braindata(brain)\n",
    "    cmap = LinearSegmentedColormap.from_list('mycmap2', ['black', 'green'])\n",
    "    plt.rcParams.update({'axes.labelsize': 'x-large',\n",
    "                         'axes.titlesize': 'x-large'})\n",
    "    fbr = plt.figure()\n",
    "    if brain.shape == (182, 218, 182):\n",
    "        x = [78, 90, 100]\n",
    "        y = [82, 107, 142]\n",
    "        z = [88, 103, 107]\n",
    "    else:\n",
    "        shap = brain.shape\n",
    "        x = [int(shap[0]*0.35), int(shap[0]*0.51), int(shap[0]*0.65)]\n",
    "        y = [int(shap[1]*0.35), int(shap[1]*0.51), int(shap[1]*0.65)]\n",
    "        z = [int(shap[2]*0.35), int(shap[2]*0.51), int(shap[2]*0.65)]\n",
    "    coords = (x, y, z)\n",
    "\n",
    "    labs = ['Sagittal Slice (YZ fixed)',\n",
    "            'Coronal Slice (XZ fixed)',\n",
    "            'Axial Slice (XY fixed)']\n",
    "    var = ['X', 'Y', 'Z']\n",
    "    # create subplot for first slice\n",
    "    # and customize all labels\n",
    "    idx = 0\n",
    "    min_val, max_val = get_min_max(brain, minthr, maxthr)\n",
    "    for i, coord in enumerate(coords):\n",
    "        for pos in coord:\n",
    "            idx += 1\n",
    "            ax = fbr.add_subplot(3, 3, idx)\n",
    "            ax.set_axis_bgcolor('black')\n",
    "            ax.set_title(var[i] + \" = \" + str(pos))\n",
    "            if i == 0:\n",
    "                image = ndimage.rotate(brain[pos, :, :], 90)\n",
    "            elif i == 1:\n",
    "                image = ndimage.rotate(brain[:, pos, :], 90)\n",
    "            else:\n",
    "                image = brain[:, :, pos]\n",
    "\n",
    "            if idx % 3 == 1:\n",
    "                ax.set_ylabel(labs[i])\n",
    "                ax.yaxis.set_ticks([0, image.shape[0]/2, image.shape[0] - 1])\n",
    "                ax.xaxis.set_ticks([0, image.shape[1]/2, image.shape[1] - 1])\n",
    "\n",
    "            if edge:\n",
    "                image = edge_map(image).data\n",
    "            ax.imshow(image, interpolation='none', cmap=cmap, alpha=1,\n",
    "                      vmin=min_val, vmax=max_val)\n",
    "\n",
    "    fbr.set_size_inches(12.5, 10.5, forward=True)\n",
    "    fbr.tight_layout()\n",
    "    return fbr\n",
    "\n",
    "\n",
    "def plot_overlays(atlas, b0, cmaps=None, minthr=2, maxthr=95, edge=False):\n",
    "    plt.rcParams.update({'axes.labelsize': 'x-large',\n",
    "                         'axes.titlesize': 'x-large'})\n",
    "    foverlay = plt.figure()\n",
    "\n",
    "    atlas = mgu.get_braindata(atlas)\n",
    "    b0 = mgu.get_braindata(b0)\n",
    "    if atlas.shape != b0.shape:\n",
    "        raise ValueError('Brains are not the same shape.')\n",
    "    if cmaps is None:\n",
    "        cmap1 = LinearSegmentedColormap.from_list('mycmap1',\n",
    "                                                  ['black', 'magenta'])\n",
    "        cmap2 = LinearSegmentedColormap.from_list('mycmap2',\n",
    "                                                  ['black', 'green'])\n",
    "        cmaps = [cmap1, cmap2]\n",
    "\n",
    "    if b0.shape == (182, 218, 182):\n",
    "        x = [78, 90, 100]\n",
    "        y = [82, 107, 142]\n",
    "        z = [88, 103, 107]\n",
    "    else:\n",
    "        shap = b0.shape\n",
    "        x = [int(shap[0]*0.35), int(shap[0]*0.51), int(shap[0]*0.65)]\n",
    "        y = [int(shap[1]*0.35), int(shap[1]*0.51), int(shap[1]*0.65)]\n",
    "        z = [int(shap[2]*0.35), int(shap[2]*0.51), int(shap[2]*0.65)]\n",
    "    coords = (x, y, z)\n",
    "\n",
    "    labs = ['Sagittal Slice (YZ fixed)',\n",
    "            'Coronal Slice (XZ fixed)',\n",
    "            'Axial Slice (XY fixed)']\n",
    "    var = ['X', 'Y', 'Z']\n",
    "    # create subplot for first slice\n",
    "    # and customize all labels\n",
    "    idx = 0\n",
    "    if edge:\n",
    "        min_val = 0\n",
    "        max_val = 1\n",
    "    else:\n",
    "        min_val, max_val = get_min_max(b0, minthr, maxthr)\n",
    "\n",
    "    for i, coord in enumerate(coords):\n",
    "        for pos in coord:\n",
    "            idx += 1\n",
    "            ax = foverlay.add_subplot(3, 3, idx)\n",
    "            ax.set_title(var[i] + \" = \" + str(pos))\n",
    "            if i == 0:\n",
    "                image = ndimage.rotate(b0[pos, :, :], 90)\n",
    "                atl = ndimage.rotate(atlas[pos, :, :], 90)\n",
    "            elif i == 1:\n",
    "                image = ndimage.rotate(b0[:, pos, :], 90)\n",
    "                atl = ndimage.rotate(atlas[:, pos, :], 90)\n",
    "            else:\n",
    "                image = b0[:, :, pos]\n",
    "                atl = atlas[:, :, pos]\n",
    "\n",
    "            if idx % 3 == 1:\n",
    "                ax.set_ylabel(labs[i])\n",
    "                ax.yaxis.set_ticks([0, image.shape[0]/2, image.shape[0] - 1])\n",
    "                ax.xaxis.set_ticks([0, image.shape[1]/2, image.shape[1] - 1])\n",
    "            if edge: \n",
    "                image = edge_map(image).data\n",
    "                image[image > 0] = max_val\n",
    "                image[image == 0] = min_val\n",
    "\n",
    "            ax.imshow(atl, interpolation='none', cmap=cmaps[0], alpha=.9)\n",
    "            ax.imshow(opaque_colorscale(cmaps[1], image, alpha=.9,\n",
    "                      vmin=min_val, vmax=max_val))\n",
    "\n",
    "    foverlay.set_size_inches(12.5, 10.5, forward=True)\n",
    "    foverlay.tight_layout()\n",
    "    return foverlay\n",
    "\n",
    "\n",
    "def get_min_max(data, minthr=2, maxthr=95):\n",
    "    '''\n",
    "    data: regmri data to threshold.\n",
    "    '''\n",
    "    min_val = np.percentile(data, minthr)\n",
    "    max_val = np.percentile(data, maxthr)\n",
    "    return (min_val.astype(float), max_val.astype(float))\n",
    "\n",
    "def loadGraph(filename, modality='dwi', verb=False):\n",
    "    if modality == 'dwi':\n",
    "        graph = nx.read_weighted_edgelist(filename, delimiter=',')\n",
    "    elif modality == 'func':\n",
    "        # read first line to int list\n",
    "        with open(filename, 'r') as fl:\n",
    "            reader = csv.reader(fl)\n",
    "            # labels\n",
    "            labs = [int(x) for x in next(reader)]\n",
    "        # read second line onwards to numpy array\n",
    "        data = np.genfromtxt(filename, dtype=float,\n",
    "            delimiter=',', skip_header=True)\n",
    "        lab_map = dict(zip(range(0, len(labs)), labs))\n",
    "        graph = nx.from_numpy_matrix(data)\n",
    "        graph = nx.relabel_nodes(graph, lab_map)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported modality.\")\n",
    "    return graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing fMRIprep outputs\n",
    "\n",
    "## Nuisance Variable Correction\n",
    "\n",
    "The fMRIprep pipeline outputs only a registered brain in MNI space. Following registration, the brain still has a number of confounds, such as noise present in the white matter and motion artifacts. To correct this, we must first nuisance correct the brain. This is accomplished through the use of GLM, where we are interested in:\n",
    "\\begin{align*}\n",
    "    \\epsilon = Y - X\\beta\n",
    "\\end{align*}\n",
    "where $Y$ is our original timeseries, and $X$ is our design matrix (confounds). Then $\\epsilon$ is the portion of the voxelwise timeseries not explained by the confounds in our design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file names as appropriate\n",
    "fmriprepdir = '/inputs/fmriprep-out/fmriprep/sub-0025427/ses-1/func'\n",
    "brain_file = '{}/sub-0025427_ses-1_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'.format(fmriprepdir)\n",
    "reg_file = '{}/sub-0025427_ses-1_task-rest_desc-confounds_regressors.tsv'.format(fmriprepdir)\n",
    "out_file = '{}/sub-0025427_ses-1_task-rest_desc-clean_bold.nii.gz'.format(fmriprepdir)\n",
    "\n",
    "fmriprep_cleaned, basic_mask = nuis_correct(brain_file, reg_file, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering parcellations to MNI152NLin2009cAsym\n",
    "\n",
    "The fMRIprep pipeline uses the MNI152NLin2009cAsym parcellation, a relatively new parcellation that is not standard in FSL nor freesurfer, and does not have parcellations natively aligned in that space generally (most people still use MNI152NLin6, such as us). We must get our parcellation into MNI152NLin2009cAsym space in order to properly downsample our timeseries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcellation = '/atlases/atlases/label/desikan_space-MNI152NLin6_res-2x2x2.nii.gz'\n",
    "parcellation_in_mni2009 = './desikan_in_mni2009.nii.gz'\n",
    "ref = '/inputs/fmriprep-out/fmriprep/sub-0025427/ses-1/func/sub-0025427_ses-1_task-rest_desc-clean_bold.nii.gz'\n",
    "ref_0 = './func_0.nii.gz'\n",
    "nib.save(img=nib.Nifti1Image(dataobj=nib.load(ref).get_data()[:,:,:,0], affine=nib.load(ref).affine, header=nib.load(ref).header), filename=ref_0)\n",
    "ndr().resample(parcellation, parcellation_in_mni2009, ref_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Quality\n",
    "\n",
    "To evaluate the quality of the registration, we check the alignment of the Desikan parcellation with that of the registered bold image in MNI152NLin2009cAsym space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plot_overlays(b0=nib.load(parcellation_in_mni2009).get_data(), atlas=nib.load(brain_file).get_data()[:,:,:,0], edge=True)\n",
    "plt.close()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great, but, close enough for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ndt().roi_timeseries(fmriprep_cleaned, parcellation_in_mni2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fmriprep_corr = np.abs(np.corrcoef(ts[0]))  # absolute correlation for connectivity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Connectomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fmriprep, ndmg-d, ndmg-f, and native space deterministic\n",
    "ndmgd_gr = nx.read_weighted_edgelist('/inputs/m3r-out/dwi/roi-connectomes/desikan_res-1x1x1/sub-0025427_ses-1_dwi_desikan_res-1x1x1_measure-spatial-ds_elist.csv', delimiter=',')\n",
    "ndmgd_adj = nx.to_numpy_matrix(natd_gr, np.array(natd_gr.nodes())[np.argsort(np.array(natd_gr.nodes()).astype(int))])\n",
    "ndmgf_adj = np.loadtxt('/inputs/m3rfunc-out/func/roi-connectomes/desikan_res-2x2x2/sub-0025427_ses-1_task-rest_bold_desikan_res-2x2x2_measure-correlation._adj.csv', delimiter=',')\n",
    "ndmgf_adj = ndmgf_adj[1:,:]\n",
    "natd_adj = np.load('./native_diff_conn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./fmriprep.csv', fmriprep_corr, delimiter=',')\n",
    "np.savetxt('./ndmgd.csv', ndmgd_adj, delimiter=',')\n",
    "np.savetxt('./ndmgf.csv', ndmgf_adj, delimiter=',')\n",
    "np.savetxt('./natd.csv', natd_adj, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
